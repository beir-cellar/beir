{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-24 21:14:03 - Loading Corpus...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ecccd52ca52481caa8bbaa5fdf93e32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8841823 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-24 21:14:27 - Loaded 8841823 TEST Documents.\n",
      "2025-05-24 21:14:27 - Doc Example: {'text': 'The presence of communication amid scientific minds was equally important to the success of the Manhattan Project as scientific intellect was. The only cloud hanging over the impressive achievement of the atomic researchers and engineers is what their success truly meant; hundreds of thousands of innocent lives obliterated.', 'title': ''}\n",
      "2025-05-24 21:14:27 - Loading Queries...\n",
      "2025-05-24 21:14:28 - Loaded 43 TEST Queries.\n",
      "2025-05-24 21:14:28 - Query Example: anthropological definition of environment\n",
      "2025-05-24 21:14:30 - Use pytorch device_name: cuda:0\n",
      "2025-05-24 21:14:30 - Load pretrained SentenceTransformer: sentence-transformers/gtr-t5-xl\n",
      "2025-05-24 21:14:42 - Query prompt: None, Passage prompt: None\n",
      "2025-05-24 21:14:42 - Query prompt name: None, Passage prompt name: None\n",
      "2025-05-24 21:14:42 - Encoding Queries...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3b6847ed5c74bd5b7780ce1d7910467",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_embeddings.shape:torch.Size([43, 768])\n",
      "2025-05-24 21:14:42 - Sorting Corpus by document length (Longest first)...\n",
      "2025-05-24 21:14:43 - Encoding Corpus in batches... Warning: This might take a while!\n",
      "2025-05-24 21:14:43 - Scoring Function: Cosine Similarity (cos_sim)\n",
      "2025-05-24 21:14:43 - Encoding Batch 1/10...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47c9aba6d59c4451a80170ef6ee0ca3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-24 21:16:42 - Encoding Batch 2/10...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07fa8a997e594cbf87ec456387928e85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-24 21:18:15 - Encoding Batch 3/10...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e598ff6349843febd3ef3fd494d4462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 44\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m#### Or load models directly from HuggingFace\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# model = DRES(models.HuggingFace(\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m#     \"intfloat/e5-large-unsupervised\",\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     40\u001b[39m \n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# model = SentenceTransformer('sentence-transformers/gtr-t5-xl')      # gtr-t5-xl\u001b[39;00m\n\u001b[32m     43\u001b[39m retriever = EvaluateRetrieval(model, score_function=\u001b[33m\"\u001b[39m\u001b[33mcos_sim\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;66;03m# or \"dot\" for dot product\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m results = \u001b[43mretriever\u001b[49m\u001b[43m.\u001b[49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueries\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[38;5;66;03m#### Evaluate your model with NDCG@k, MAP@K, Recall@K and Precision@K  where k = [1,3,5,10,100,1000]\u001b[39;00m\n\u001b[32m     47\u001b[39m ndcg, _map, recall, precision = retriever.evaluate(qrels, results, retriever.k_values)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/richard/taggerv2/test/test6/beir/beir/retrieval/evaluation.py:30\u001b[39m, in \u001b[36mEvaluateRetrieval.retrieve\u001b[39m\u001b[34m(self, corpus, queries, **kwargs)\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.retriever:\n\u001b[32m     29\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mModel/Technique has not been provided!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretriever\u001b[49m\u001b[43m.\u001b[49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscore_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/richard/taggerv2/test/test6/beir/beir/retrieval/search/dense/exact_search.py:82\u001b[39m, in \u001b[36mDenseRetrievalExactSearch.search\u001b[39m\u001b[34m(self, corpus, queries, top_k, score_function, return_sorted, **kwargs)\u001b[39m\n\u001b[32m     79\u001b[39m corpus_end_idx = \u001b[38;5;28mmin\u001b[39m(corpus_start_idx + \u001b[38;5;28mself\u001b[39m.corpus_chunk_size, \u001b[38;5;28mlen\u001b[39m(corpus))\n\u001b[32m     81\u001b[39m \u001b[38;5;66;03m# Encode chunk of corpus\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m sub_corpus_embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode_corpus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcorpus_start_idx\u001b[49m\u001b[43m:\u001b[49m\u001b[43mcorpus_end_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[38;5;66;03m# print(f'sub_corpus_embeddings.shape:{sub_corpus_embeddings.shape}')\u001b[39;00m\n\u001b[32m     90\u001b[39m \n\u001b[32m     91\u001b[39m \u001b[38;5;66;03m# Compute similarites using either cosine-similarity or dot product\u001b[39;00m\n\u001b[32m     92\u001b[39m cos_scores = \u001b[38;5;28mself\u001b[39m.score_functions[score_function](query_embeddings, sub_corpus_embeddings)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/richard/taggerv2/test/test6/beir/beir/retrieval/models/sentence_bert.py:107\u001b[39m, in \u001b[36mSentenceBERT.encode_corpus\u001b[39m\u001b[34m(self, corpus, batch_size, **kwargs)\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mencode_corpus\u001b[39m(\n\u001b[32m    101\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    102\u001b[39m     corpus: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] | \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mlist\u001b[39m] | \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[32m    103\u001b[39m     batch_size: \u001b[38;5;28mint\u001b[39m = \u001b[32m8\u001b[39m,\n\u001b[32m    104\u001b[39m     **kwargs,\n\u001b[32m    105\u001b[39m ) -> \u001b[38;5;28mlist\u001b[39m[Tensor] | np.ndarray | Tensor:\n\u001b[32m    106\u001b[39m     sentences = extract_corpus_sentences(corpus=corpus, sep=\u001b[38;5;28mself\u001b[39m.sep)\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdoc_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m        \u001b[49m\u001b[43msentences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdoc_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompt_name\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdoc_prompt_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/local/richard/miniconda3/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py:653\u001b[39m, in \u001b[36mSentenceTransformer.encode\u001b[39m\u001b[34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, **kwargs)\u001b[39m\n\u001b[32m    651\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m start_index \u001b[38;5;129;01min\u001b[39;00m trange(\u001b[32m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(sentences), batch_size, desc=\u001b[33m\"\u001b[39m\u001b[33mBatches\u001b[39m\u001b[33m\"\u001b[39m, disable=\u001b[38;5;129;01mnot\u001b[39;00m show_progress_bar):\n\u001b[32m    652\u001b[39m     sentences_batch = sentences_sorted[start_index : start_index + batch_size]\n\u001b[32m--> \u001b[39m\u001b[32m653\u001b[39m     features = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentences_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    654\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.device.type == \u001b[33m\"\u001b[39m\u001b[33mhpu\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    655\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m features:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/local/richard/miniconda3/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py:1124\u001b[39m, in \u001b[36mSentenceTransformer.tokenize\u001b[39m\u001b[34m(self, texts)\u001b[39m\n\u001b[32m   1113\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mtokenize\u001b[39m(\u001b[38;5;28mself\u001b[39m, texts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] | \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m] | \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]]) -> \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Tensor]:\n\u001b[32m   1114\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1115\u001b[39m \u001b[33;03m    Tokenizes the texts.\u001b[39;00m\n\u001b[32m   1116\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1122\u001b[39m \u001b[33;03m            \"attention_mask\", and \"token_type_ids\".\u001b[39;00m\n\u001b[32m   1123\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1124\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_first_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/local/richard/miniconda3/lib/python3.12/site-packages/sentence_transformers/models/Transformer.py:500\u001b[39m, in \u001b[36mTransformer.tokenize\u001b[39m\u001b[34m(self, texts, padding)\u001b[39m\n\u001b[32m    496\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.do_lower_case:\n\u001b[32m    497\u001b[39m     to_tokenize = [[s.lower() \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m col] \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m to_tokenize]\n\u001b[32m    499\u001b[39m output.update(\n\u001b[32m--> \u001b[39m\u001b[32m500\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43mto_tokenize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    503\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlongest_first\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    506\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    507\u001b[39m )\n\u001b[32m    508\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/local/richard/miniconda3/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2887\u001b[39m, in \u001b[36mPreTrainedTokenizerBase.__call__\u001b[39m\u001b[34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[39m\n\u001b[32m   2885\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._in_target_context_manager:\n\u001b[32m   2886\u001b[39m         \u001b[38;5;28mself\u001b[39m._switch_to_input_mode()\n\u001b[32m-> \u001b[39m\u001b[32m2887\u001b[39m     encodings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2888\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2889\u001b[39m     \u001b[38;5;28mself\u001b[39m._switch_to_target_mode()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/local/richard/miniconda3/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2975\u001b[39m, in \u001b[36mPreTrainedTokenizerBase._call_one\u001b[39m\u001b[34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[39m\n\u001b[32m   2970\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2971\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mbatch length of `text`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not match batch length of `text_pair`:\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2972\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text_pair)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2973\u001b[39m         )\n\u001b[32m   2974\u001b[39m     batch_text_or_text_pairs = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(text, text_pair)) \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m text\n\u001b[32m-> \u001b[39m\u001b[32m2975\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbatch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2976\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2977\u001b[39m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2978\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2979\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2980\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2981\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2982\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2983\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2984\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2985\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2986\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2987\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2988\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2989\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2990\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2991\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2992\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2993\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2994\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2995\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2996\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2997\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.encode_plus(\n\u001b[32m   2998\u001b[39m         text=text,\n\u001b[32m   2999\u001b[39m         text_pair=text_pair,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3017\u001b[39m         **kwargs,\n\u001b[32m   3018\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/local/richard/miniconda3/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:3177\u001b[39m, in \u001b[36mPreTrainedTokenizerBase.batch_encode_plus\u001b[39m\u001b[34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[39m\n\u001b[32m   3167\u001b[39m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[32m   3168\u001b[39m padding_strategy, truncation_strategy, max_length, kwargs = \u001b[38;5;28mself\u001b[39m._get_padding_truncation_strategies(\n\u001b[32m   3169\u001b[39m     padding=padding,\n\u001b[32m   3170\u001b[39m     truncation=truncation,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3174\u001b[39m     **kwargs,\n\u001b[32m   3175\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m3177\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_batch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3178\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3179\u001b[39m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3180\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3181\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3182\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3183\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3184\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3185\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3186\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3187\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3188\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3189\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3190\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3191\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3192\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3193\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3194\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3195\u001b[39m \u001b[43m    \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3196\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3197\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/local/richard/miniconda3/lib/python3.12/site-packages/transformers/tokenization_utils_fast.py:552\u001b[39m, in \u001b[36mPreTrainedTokenizerFast._batch_encode_plus\u001b[39m\u001b[34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens)\u001b[39m\n\u001b[32m    539\u001b[39m encodings = \u001b[38;5;28mself\u001b[39m._tokenizer.encode_batch(\n\u001b[32m    540\u001b[39m     batch_text_or_text_pairs,\n\u001b[32m    541\u001b[39m     add_special_tokens=add_special_tokens,\n\u001b[32m    542\u001b[39m     is_pretokenized=is_split_into_words,\n\u001b[32m    543\u001b[39m )\n\u001b[32m    545\u001b[39m \u001b[38;5;66;03m# Convert encoding to dict\u001b[39;00m\n\u001b[32m    546\u001b[39m \u001b[38;5;66;03m# `Tokens` has type: Tuple[\u001b[39;00m\n\u001b[32m    547\u001b[39m \u001b[38;5;66;03m#                       List[Dict[str, List[List[int]]]] or List[Dict[str, 2D-Tensor]],\u001b[39;00m\n\u001b[32m    548\u001b[39m \u001b[38;5;66;03m#                       List[EncodingFast]\u001b[39;00m\n\u001b[32m    549\u001b[39m \u001b[38;5;66;03m#                    ]\u001b[39;00m\n\u001b[32m    550\u001b[39m \u001b[38;5;66;03m# with nested dimensions corresponding to batch, overflows, sequence length\u001b[39;00m\n\u001b[32m    551\u001b[39m tokens_and_encodings = [\n\u001b[32m--> \u001b[39m\u001b[32m552\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_encoding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    553\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    555\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    556\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    557\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    558\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    559\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    560\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    561\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    562\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m encoding \u001b[38;5;129;01min\u001b[39;00m encodings\n\u001b[32m    563\u001b[39m ]\n\u001b[32m    565\u001b[39m \u001b[38;5;66;03m# Convert the output to have dict[list] from list[dict] and remove the additional overflows dimension\u001b[39;00m\n\u001b[32m    566\u001b[39m \u001b[38;5;66;03m# From (variable) shape (batch, overflows, sequence length) to ~ (batch * overflows, sequence length)\u001b[39;00m\n\u001b[32m    567\u001b[39m \u001b[38;5;66;03m# (we say ~ because the number of overflow varies with the example in the batch)\u001b[39;00m\n\u001b[32m    568\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    569\u001b[39m \u001b[38;5;66;03m# To match each overflowing sample with the original sample in the batch\u001b[39;00m\n\u001b[32m    570\u001b[39m \u001b[38;5;66;03m# we add an overflow_to_sample_mapping array (see below)\u001b[39;00m\n\u001b[32m    571\u001b[39m sanitized_tokens = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/local/richard/miniconda3/lib/python3.12/site-packages/transformers/tokenization_utils_fast.py:337\u001b[39m, in \u001b[36mPreTrainedTokenizerFast._convert_encoding\u001b[39m\u001b[34m(self, encoding, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose)\u001b[39m\n\u001b[32m    335\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m return_offsets_mapping:\n\u001b[32m    336\u001b[39m         encoding_dict[\u001b[33m\"\u001b[39m\u001b[33moffset_mapping\u001b[39m\u001b[33m\"\u001b[39m].append(e.offsets)\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m return_length:\n\u001b[32m    338\u001b[39m         encoding_dict[\u001b[33m\"\u001b[39m\u001b[33mlength\u001b[39m\u001b[33m\"\u001b[39m].append(\u001b[38;5;28mlen\u001b[39m(e.ids))\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m encoding_dict, encodings\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from beir import util, LoggingHandler\n",
    "from beir.retrieval import models\n",
    "from beir.datasets.data_loader import GenericDataLoader\n",
    "from beir.retrieval.evaluation import EvaluateRetrieval\n",
    "from beir.retrieval.search.dense import DenseRetrievalExactSearch as DRES\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import logging\n",
    "import pathlib, os\n",
    "\n",
    "#### Just some code to print debug information to stdout\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                    level=logging.INFO,\n",
    "                    handlers=[LoggingHandler()])\n",
    "#### /print debug information to stdout\n",
    "\n",
    "#### Download scifact.zip dataset and unzip the dataset\n",
    "dataset = \"MSMARCO\"\n",
    "url = f\"https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/{dataset}.zip\"\n",
    "# out_dir = os.path.join('/data/richard/taggerv2/test/test6/beir/outputs', \"datasets\")\n",
    "data_path = '/data/richard/taggerv2/test/test6/beir/outputs/datasets/msmarco'\n",
    "\n",
    "#### Provide the data_path where scifact has been downloaded and unzipped\n",
    "corpus, queries, qrels = GenericDataLoader(data_folder=data_path).load(split=\"test\")\n",
    "\n",
    "#### Load the SBERT model and retrieve using cosine-similarity\n",
    "# model = DRES(models.SentenceBERT(\"Alibaba-NLP/gte-modernbert-base\"), batch_size=16)\n",
    "# model = DRES(models.SentenceBERT(\"msmarco-roberta-base-ance-firstp\"))\n",
    "model = DRES(models.SentenceBERT('sentence-transformers/gtr-t5-xl'))\n",
    "\n",
    "#### Or load models directly from HuggingFace\n",
    "# model = DRES(models.HuggingFace(\n",
    "#     \"intfloat/e5-large-unsupervised\",\n",
    "#     max_length=512,\n",
    "#     pooling=\"mean\",\n",
    "#     normalize=True,\n",
    "#     prompts={\"query\": \"query: \", \"passage\": \"passage: \"}), batch_size=16)\n",
    "\n",
    "# model = SentenceTransformer('sentence-transformers/gtr-t5-xl')      # gtr-t5-xl\n",
    "\n",
    "retriever = EvaluateRetrieval(model, score_function=\"cos_sim\") # or \"dot\" for dot product\n",
    "results = retriever.retrieve(corpus, queries)\n",
    "\n",
    "#### Evaluate your model with NDCG@k, MAP@K, Recall@K and Precision@K  where k = [1,3,5,10,100,1000]\n",
    "ndcg, _map, recall, precision = retriever.evaluate(qrels, results, retriever.k_values)\n",
    "print(f'ndcg, _map, recall, precision: {ndcg, _map, recall, precision}')\n",
    "mrr = retriever.evaluate_custom(qrels, results, retriever.k_values, metric=\"mrr\")\n",
    "\n",
    "### If you want to save your results and runfile (useful for reranking)\n",
    "results_dir = os.path.join(pathlib.Path(__file__).parent.absolute(), \"results\")\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "#### Save the evaluation runfile & results\n",
    "util.save_runfile(os.path.join(results_dir, f\"{dataset}.run.trec\"), results)\n",
    "util.save_results(os.path.join(results_dir, f\"{dataset}.json\"), ndcg, _map, recall, precision, mrr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/richard/taggerv2/test/test6/beir/beir/util.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-24 23:11:36 - Loading Corpus...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3db0f868191546948dcfd0cf8d5a4db0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8841823 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-24 23:12:00 - Loaded 8841823 TEST Documents.\n",
      "2025-05-24 23:12:00 - Doc Example: {'text': 'The presence of communication amid scientific minds was equally important to the success of the Manhattan Project as scientific intellect was. The only cloud hanging over the impressive achievement of the atomic researchers and engineers is what their success truly meant; hundreds of thousands of innocent lives obliterated.', 'title': ''}\n",
      "2025-05-24 23:12:00 - Loading Queries...\n",
      "2025-05-24 23:12:01 - Loaded 43 TEST Queries.\n",
      "2025-05-24 23:12:01 - Query Example: anthropological definition of environment\n"
     ]
    }
   ],
   "source": [
    "from beir import util, LoggingHandler\n",
    "from beir.retrieval import models\n",
    "from beir.datasets.data_loader import GenericDataLoader\n",
    "from beir.retrieval.evaluation import EvaluateRetrieval\n",
    "from beir.retrieval.search.dense import DenseRetrievalExactSearch as DRES\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import logging\n",
    "import pathlib, os\n",
    "\n",
    "#### Just some code to print debug information to stdout\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                    level=logging.INFO,\n",
    "                    handlers=[LoggingHandler()])\n",
    "#### /print debug information to stdout\n",
    "\n",
    "#### Download scifact.zip dataset and unzip the dataset\n",
    "dataset = \"MSMARCO\"\n",
    "url = f\"https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/{dataset}.zip\"\n",
    "# out_dir = os.path.join('/data/richard/taggerv2/test/test6/beir/outputs', \"datasets\")\n",
    "data_path = '/data/richard/taggerv2/test/test6/beir/outputs/datasets/msmarco'\n",
    "\n",
    "#### Provide the data_path where scifact has been downloaded and unzipped\n",
    "corpus, queries, qrels = GenericDataLoader(data_folder=data_path).load(split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 The Manhattan Project and its atomic bomb helped bring an end to World War II. Its legacy of peaceful uses of atomic energy continues to have an impact on history and science.\n"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "\n",
    "print(list(corpus.keys())[i], list(corpus.values())[i]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47923 {'1200258': 2, '1236611': 0, '1296110': 1, '1300989': 1, '1354790': 1, '1463436': 0, '1507610': 1, '1508658': 1, '1669816': 1, '1681331': 2, '1681332': 1, '1681334': 2, '1681335': 1, '1681336': 1, '1681337': 1, '1681339': 1, '1717546': 0, '1767240': 1, '1868437': 2, '1868438': 1, '1923153': 1, '1960681': 1, '2044900': 1, '2061700': 0, '2061702': 0, '2061706': 0, '2148997': 1, '2157582': 1, '217594': 0, '2408264': 0, '2477210': 2, '2477211': 1, '2655670': 2, '2719555': 1, '2749477': 1, '2772864': 1, '2831044': 0, '2831045': 0, '284591': 2, '2917510': 1, '3196227': 0, '320920': 1, '3246976': 1, '3348830': 0, '3348837': 1, '3348838': 1, '3573382': 0, '3630933': 1, '3630935': 2, '3694265': 1, '3748434': 2, '388338': 0, '3986046': 1, '4081982': 1, '4143232': 2, '4257346': 1, '4297613': 0, '4297620': 1, '4321228': 1, '4321230': 2, '4416477': 1, '4490071': 0, '4652165': 0, '4652795': 2, '4655679': 0, '4684891': 1, '4684893': 2, '4684895': 1, '473807': 3, '473809': 1, '4778734': 1, '4793758': 1, '4997370': 2, '5032362': 1, '5051722': 1, '5053382': 1, '5055000': 2, '5065570': 0, '5137402': 1, '5144927': 0, '5147527': 1, '5147529': 1, '5147530': 1, '525511': 1, '5417577': 1, '5417578': 0, '5417580': 1, '5417582': 3, '5878045': 0, '5949690': 1, '5966643': 2, '5966645': 0, '6111296': 1, '611271': 2, '6139476': 0, '618555': 2, '618556': 3, '618559': 1, '6191': 3, '6213244': 0, '6241147': 2, '6241148': 2, '6241150': 1, '6241151': 2, '6241152': 3, '6241153': 2, '6241154': 2, '6378779': 2, '6643066': 3, '6652175': 1, '6696631': 1, '6813699': 1, '6919836': 2, '6919837': 0, '7109642': 2, '7507613': 0, '7644552': 2, '766025': 2, '769287': 0, '778272': 2, '7786719': 1, '7890942': 1, '7891160': 1, '7914826': 2, '8214977': 1, '829484': 1, '8327407': 1, '8327408': 1, '8348762': 1, '84017': 1, '8418681': 2, '8418683': 0, '8418684': 1, '8418686': 1, '8421421': 2, '8619129': 0, '8641104': 3, '8641107': 1, '8659158': 1, '8727556': 0, '8836262': 2, '913042': 1, '986177': 2}\n"
     ]
    }
   ],
   "source": [
    "print(list(qrels.keys())[i], list(qrels.values())[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "axon terminals or synaptic knob definition Some axons are over 1 meter long. 1  Display the top half of a transparency of Master 2.2, Neurons Interact with Other Neurons Through Synapses. Point out that the axon terminals of one neuron end near the dendrites of another neuron. 2  Reveal the lower portion of Master 2.2 showing the synapse. This signal is then propagated along the axon (and not, say, back to its dendrites) until it reaches its axon terminals. An action potential travels along the axon quickly, moving at rates up to 150 meters (or roughly 500 feet) per second. Conduction ends at the axon terminals.\n"
     ]
    }
   ],
   "source": [
    "print(, , )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'axon terminals or synaptic knob definition'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries['47923']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This mechanism, called conduction, is how the cell body of a neuron communicates with its own terminals via the axon. Communication between neurons is achieved at synapses by the process of neurotransmission. To begin conduction, an action potential is generated near the cell body portion of the axon.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus['1236611']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This signal is then propagated along the axon (and not, say, back to its dendrites) until it reaches its axon terminals. An action potential travels along the axon quickly, moving at rates up to 150 meters (or roughly 500 feet) per second. Conduction ends at the axon terminals.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus['1296110']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GTR-T5-XL\n",
    "\n",
    "2025-05-25 01:23:29 - NDCG@1: 0.2259                                                                          [9/1797]\n",
    "2025-05-25 01:23:29 - NDCG@3: 0.3397                                                                                  \n",
    "2025-05-25 01:23:29 - NDCG@5: 0.3833                                                                                  \n",
    "2025-05-25 01:23:29 - NDCG@10: 0.4237                                                                                 \n",
    "2025-05-25 01:23:29 - NDCG@100: 0.4792                                                                                \n",
    "2025-05-25 01:23:29 - NDCG@1000: 0.4896                                                                               \n",
    "2025-05-25 01:23:29 -                                                                                                 \n",
    "                                                                                                                      \n",
    "2025-05-25 01:23:29 - MAP@1: 0.2196                                                                                   \n",
    "2025-05-25 01:23:29 - MAP@3: 0.3088                                                                                   \n",
    "2025-05-25 01:23:29 - MAP@5: 0.3334\n",
    "2025-05-25 01:23:29 - MAP@10: 0.3503\n",
    "2025-05-25 01:23:29 - MAP@100: 0.3620\n",
    "2025-05-25 01:23:29 - MAP@1000: 0.3624\n",
    "2025-05-25 01:23:29 - \n",
    "\n",
    "2025-05-25 01:23:29 - Recall@1: 0.2196\n",
    "2025-05-25 01:23:29 - Recall@3: 0.4225\n",
    "2025-05-25 01:23:29 - Recall@5: 0.5269\n",
    "2025-05-25 01:23:29 - Recall@10: 0.6496\n",
    "2025-05-25 01:23:29 - Recall@100: 0.9049\n",
    "2025-05-25 01:23:29 - Recall@1000: 0.9837\n",
    "2025-05-25 01:23:29 - \n",
    "\n",
    "2025-05-25 01:23:29 - P@1: 0.2259\n",
    "2025-05-25 01:23:29 - P@3: 0.1463\n",
    "2025-05-25 01:23:29 - P@5: 0.1098\n",
    "2025-05-25 01:23:29 - P@10: 0.0680\n",
    "2025-05-25 01:23:29 - P@100: 0.0096\n",
    "2025-05-25 01:23:29 - P@1000: 0.0010\n",
    "ndcg, _map, recall, precision: ({'NDCG@1': 0.22593, 'NDCG@3': 0.33971, 'NDCG@5': 0.38328, 'NDCG@10': 0.42367, 'NDCG@10\n",
    "0': 0.47919, 'NDCG@1000': 0.48962}, {'MAP@1': 0.2196, 'MAP@3': 0.30877, 'MAP@5': 0.33341, 'MAP@10': 0.35033, 'MAP@100'\n",
    ": 0.36197, 'MAP@1000': 0.36241}, {'Recall@1': 0.2196, 'Recall@3': 0.42253, 'Recall@5': 0.52685, 'Recall@10': 0.64965, \n",
    "'Recall@100': 0.90487, 'Recall@1000': 0.9837}, {'P@1': 0.22593, 'P@3': 0.14632, 'P@5': 0.1098, 'P@10': 0.06802, 'P@100\n",
    "': 0.00958, 'P@1000': 0.00105})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANCE\n",
    "\n",
    "2025-05-25 02:03:08 - NDCG@1: 0.1973                                                                                  \n",
    "2025-05-25 02:03:08 - NDCG@3: 0.2982                                                                          [8/1823]\n",
    "2025-05-25 02:03:08 - NDCG@5: 0.3351                                                                                  \n",
    "2025-05-25 02:03:08 - NDCG@10: 0.3705                                                                                 \n",
    "2025-05-25 02:03:08 - NDCG@100: 0.4283                                                                                \n",
    "2025-05-25 02:03:08 - NDCG@1000: 0.4432                                                                               \n",
    "2025-05-25 02:03:08 -                                                                                                 \n",
    "                                                                                                                      \n",
    "2025-05-25 02:03:08 - MAP@1: 0.1913                                                                                   \n",
    "2025-05-25 02:03:08 - MAP@3: 0.2706                                                                                   \n",
    "2025-05-25 02:03:08 - MAP@5: 0.2912\n",
    "2025-05-25 02:03:08 - MAP@10: 0.3062\n",
    "2025-05-25 02:03:08 - MAP@100: 0.3180\n",
    "2025-05-25 02:03:08 - MAP@1000: 0.3186\n",
    "2025-05-25 02:03:08 - \n",
    "\n",
    "2025-05-25 02:03:08 - Recall@1: 0.1913\n",
    "2025-05-25 02:03:08 - Recall@3: 0.3715\n",
    "2025-05-25 02:03:08 - Recall@5: 0.4603\n",
    "2025-05-25 02:03:08 - Recall@10: 0.5674\n",
    "2025-05-25 02:03:08 - Recall@100: 0.8364\n",
    "2025-05-25 02:03:08 - Recall@1000: 0.9508\n",
    "2025-05-25 02:03:08 - \n",
    "\n",
    "2025-05-25 02:03:08 - P@1: 0.1973\n",
    "2025-05-25 02:03:08 - P@3: 0.1284\n",
    "2025-05-25 02:03:08 - P@5: 0.0957\n",
    "2025-05-25 02:03:08 - P@10: 0.0594\n",
    "2025-05-25 02:03:08 - P@100: 0.0088\n",
    "2025-05-25 02:03:08 - P@1000: 0.0010\n",
    "ndcg, _map, recall, precision: ({'NDCG@1': 0.19728, 'NDCG@3': 0.29821, 'NDCG@5': 0.33507, 'NDCG@10': 0.37051, 'NDCG@10\n",
    "0': 0.42833, 'NDCG@1000': 0.44317}, {'MAP@1': 0.19134, 'MAP@3': 0.27064, 'MAP@5': 0.29118, 'MAP@10': 0.3062, 'MAP@100$\n",
    ": 0.31802, 'MAP@1000': 0.3186}, {'Recall@1': 0.19134, 'Recall@3': 0.37155, 'Recall@5': 0.46035, 'Recall@10': 0.56741, \n",
    "'Recall@100': 0.83644, 'Recall@1000': 0.95079}, {'P@1': 0.19728, 'P@3': 0.12841, 'P@5': 0.0957, 'P@10': 0.05937, 'P@10\n",
    "0': 0.00883, 'P@1000': 0.00101})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BGE\n",
    "\n",
    "2025-05-25 02:51:45 - NDCG@1: 0.2329                                                                                  \n",
    "2025-05-25 02:51:45 - NDCG@3: 0.3435                                                                                  \n",
    "2025-05-25 02:51:45 - NDCG@5: 0.3833                                                                                  \n",
    "2025-05-25 02:51:45 - NDCG@10: 0.4206                                                                                 \n",
    "2025-05-25 02:51:45 - NDCG@100: 0.4764                                                                                \n",
    "2025-05-25 02:51:45 - NDCG@1000: 0.4880                                                                               \n",
    "2025-05-25 02:51:45 -                                                                                                 \n",
    "                                                                                                                      \n",
    "2025-05-25 02:51:45 - MAP@1: 0.2272                                                                                   \n",
    "2025-05-25 02:51:45 - MAP@3: 0.3136                                                                                   \n",
    "2025-05-25 02:51:45 - MAP@5: 0.3359                                                                                   \n",
    "2025-05-25 02:51:45 - MAP@10: 0.3516                                                                                  \n",
    "2025-05-25 02:51:45 - MAP@100: 0.3634                                                                                 \n",
    "2025-05-25 02:51:45 - MAP@1000: 0.3639                                                                                \n",
    "2025-05-25 02:51:45 -                                                                                                 \n",
    "                                                                                                                      \n",
    "2025-05-25 02:51:45 - Recall@1: 0.2272                                                                                \n",
    "2025-05-25 02:51:45 - Recall@3: 0.4232                                                                                \n",
    "2025-05-25 02:51:45 - Recall@5: 0.5189                                                                                \n",
    "2025-05-25 02:51:45 - Recall@10: 0.6320 \n",
    "2025-05-25 02:51:45 - Recall@100: 0.8881 \n",
    "2025-05-25 02:51:45 - Recall@1000: 0.9764\n",
    "2025-05-25 02:51:45 -                                      \n",
    "                                                           \n",
    "2025-05-25 02:51:45 - P@1: 0.2329                          \n",
    "2025-05-25 02:51:45 - P@3: 0.1461     \n",
    "2025-05-25 02:51:45 - P@5: 0.1078      \n",
    "2025-05-25 02:51:45 - P@10: 0.0660      \n",
    "2025-05-25 02:51:45 - P@100: 0.0094      \n",
    "2025-05-25 02:51:45 - P@1000: 0.0010                                                                                  \n",
    "ndcg, _map, recall, precision: ({'NDCG@1': 0.23295, 'NDCG@3': 0.34346, 'NDCG@5': 0.38334, 'NDCG@10': 0.42064, 'NDCG@10\n",
    "0': 0.4764, 'NDCG@1000': 0.48802}, {'MAP@1': 0.22718, 'MAP@3': 0.31359, 'MAP@5': 0.3359, 'MAP@10': 0.35162, 'MAP@100':\n",
    " 0.36339, 'MAP@1000': 0.36387}, {'Recall@1': 0.22718, 'Recall@3': 0.42315, 'Recall@5': 0.5189, 'Recall@10': 0.63197, '\n",
    "Recall@100': 0.88812, 'Recall@1000': 0.97636}, {'P@1': 0.23295, 'P@3': 0.14613, 'P@5': 0.10782, 'P@10': 0.06602, 'P@10\n",
    "0': 0.00939, 'P@1000': 0.00104})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BGE llm-embedder\n",
    "\n",
    "2025-06-01 20:18:17 - NDCG@1: 0.2365                                                                                        \n",
    "2025-06-01 20:18:17 - NDCG@3: 0.3399                                                                                        \n",
    "2025-06-01 20:18:17 - NDCG@5: 0.3787                                                                                        \n",
    "2025-06-01 20:18:17 - NDCG@10: 0.4191                                                                                       \n",
    "2025-06-01 20:18:17 - NDCG@100: 0.4722                                                                                      \n",
    "2025-06-01 20:18:17 - NDCG@1000: 0.4849                                                                                     \n",
    "2025-06-01 20:18:17 -                                                                                                       \n",
    "                                                                                                                            \n",
    "2025-06-01 20:18:17 - MAP@1: 0.2293                                                                                         \n",
    "2025-06-01 20:18:17 - MAP@3: 0.3114                                                                                         \n",
    "2025-06-01 20:18:17 - MAP@5: 0.3330                                                                                         \n",
    "2025-06-01 20:18:17 - MAP@10: 0.3502                                                                                        \n",
    "2025-06-01 20:18:17 - MAP@100: 0.3612\n",
    "2025-06-01 20:18:17 - MAP@1000: 0.3617\n",
    "2025-06-01 20:18:17 - \n",
    "\n",
    "2025-06-01 20:18:17 - Recall@1: 0.2293\n",
    "2025-06-01 20:18:17 - Recall@3: 0.4153\n",
    "2025-06-01 20:18:17 - Recall@5: 0.5086\n",
    "2025-06-01 20:18:17 - Recall@10: 0.6310\n",
    "2025-06-01 20:18:17 - Recall@100: 0.8763\n",
    "2025-06-01 20:18:17 - Recall@1000: 0.9734\n",
    "2025-06-01 20:18:17 - \n",
    "\n",
    "2025-06-01 20:18:17 - P@1: 0.2365\n",
    "2025-06-01 20:18:17 - P@3: 0.1437\n",
    "2025-06-01 20:18:17 - P@5: 0.1058\n",
    "2025-06-01 20:18:17 - P@10: 0.0659\n",
    "2025-06-01 20:18:17 - P@100: 0.0093\n",
    "2025-06-01 20:18:17 - P@1000: 0.0010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GTR-SFT\n",
    "\n",
    "2025-06-01 21:28:32 - NDCG@1: 0.0199                                                                                          \n",
    "2025-06-01 21:28:32 - NDCG@3: 0.0297                                                                                          \n",
    "2025-06-01 21:28:32 - NDCG@5: 0.0345                                                                                          \n",
    "2025-06-01 21:28:32 - NDCG@10: 0.0398                                                                                         \n",
    "2025-06-01 21:28:32 - NDCG@100: 0.0583                                                                                        \n",
    "2025-06-01 21:28:32 - NDCG@1000: 0.0764                                                                                       \n",
    "2025-06-01 21:28:32 -                                                                                                         \n",
    "                                                                                                                              \n",
    "2025-06-01 21:28:32 - MAP@1: 0.0188                                                                                           \n",
    "2025-06-01 21:28:32 - MAP@3: 0.0267                                                                                           \n",
    "2025-06-01 21:28:32 - MAP@5: 0.0293                                                                                           \n",
    "2025-06-01 21:28:32 - MAP@10: 0.0315                                                                                          \n",
    "2025-06-01 21:28:32 - MAP@100: 0.0347                                                                                         \n",
    "2025-06-01 21:28:32 - MAP@1000: 0.0352                                                                                        \n",
    "2025-06-01 21:28:32 -                                          \n",
    "                               \n",
    "2025-06-01 21:28:32 - Recall@1: 0.0188\n",
    "2025-06-01 21:28:32 - Recall@3: 0.0370\n",
    "2025-06-01 21:28:32 - Recall@5: 0.0487\n",
    "2025-06-01 21:28:32 - Recall@10: 0.0649\n",
    "2025-06-01 21:28:32 - Recall@100: 0.1576\n",
    "2025-06-01 21:28:32 - Recall@1000: 0.3070\n",
    "2025-06-01 21:28:32 -                                          \n",
    "                                                                                                                              2025-06-01 21:28:32 - P@1: 0.0199                                                                                             \n",
    "2025-06-01 21:28:32 - P@3: 0.0130                                                                                             \n",
    "2025-06-01 21:28:32 - P@5: 0.0103                                                                                             2025-06-01 21:28:32 - P@10: 0.0069\n",
    "2025-06-01 21:28:32 - P@100: 0.0017\n",
    "2025-06-01 21:28:32 - P@1000: 0.0003"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
