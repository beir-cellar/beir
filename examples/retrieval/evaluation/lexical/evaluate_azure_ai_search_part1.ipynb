{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BEIR Benchmarking for Azure AI Search (Part1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate Index\n",
    "recreate_index = False\n",
    "\n",
    "# datasets to evaluate\n",
    "dataset_name = \"scifact\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variabls from .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download BEIR datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beir import util, LoggingHandler\n",
    "from beir.datasets.data_loader import GenericDataLoader\n",
    "from beir.retrieval.evaluation import EvaluateRetrieval\n",
    "from beir.retrieval.search.lexical import BM25Search as BM25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/{}.zip\".format(dataset_name)\n",
    "out_dir = \"./datasets\"\n",
    "data_path = util.download_and_unzip(url, out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus, queries, qrels = GenericDataLoader(data_path).load(split=\"test\")# pull data from corpus and queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure AI Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Azure AI Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents.indexes import SearchIndexClient \n",
    "from azure.search.documents import SearchClient\n",
    "\n",
    "service_name = \"benchmark-ai-search\"\n",
    "index_name = dataset_name  + \"-vector\"\n",
    "\n",
    "admin_key = os.environ[\"SEARCH_ADMIN_KEY\"]\n",
    "endpoint = \"https://{}.search.windows.net/\".format(service_name)\n",
    "\n",
    "admin_client = SearchIndexClient(endpoint=endpoint,\n",
    "                    index_name=index_name,\n",
    "                    credential=AzureKeyCredential(admin_key))\n",
    "\n",
    "search_client = SearchClient(endpoint=endpoint,\n",
    "                    index_name=index_name,\n",
    "                    credential=AzureKeyCredential(admin_key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.models import (\n",
    "    QueryAnswerType,\n",
    "    QueryCaptionType,\n",
    "    QueryCaptionResult,\n",
    "    QueryAnswerResult,\n",
    "    SemanticErrorMode,\n",
    "    SemanticErrorReason,\n",
    "    SemanticSearchResultsType,\n",
    "    QueryType,\n",
    "    VectorizedQuery,\n",
    "    VectorQuery,\n",
    "    VectorFilterMode,    \n",
    ")\n",
    "from azure.search.documents.indexes.models import (  \n",
    "    ExhaustiveKnnAlgorithmConfiguration,\n",
    "    ExhaustiveKnnParameters,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    HnswParameters,\n",
    "    SemanticConfiguration,  \n",
    "    SemanticField,  \n",
    "    VectorSearch,  \n",
    "    VectorSearchAlgorithmKind,  \n",
    "    VectorSearchAlgorithmMetric,  \n",
    "    VectorSearchProfile,  \n",
    "    SemanticSearch,\n",
    "    SemanticPrioritizedFields,\n",
    "    CorsOptions\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(QueryType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if recreate_index==True:\n",
    "    try:\n",
    "        admin_client.delete_index(index_name)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure vector search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the vector search configuration  \n",
    "vector_search = VectorSearch(\n",
    "    algorithms=[\n",
    "        HnswAlgorithmConfiguration(\n",
    "            name=\"myHnsw\",\n",
    "            kind=VectorSearchAlgorithmKind.HNSW,\n",
    "            parameters=HnswParameters(\n",
    "                m=4,\n",
    "                ef_construction=400,\n",
    "                ef_search=500,\n",
    "                metric=VectorSearchAlgorithmMetric.COSINE\n",
    "            )\n",
    "        ),\n",
    "        ExhaustiveKnnAlgorithmConfiguration(\n",
    "            name=\"myExhaustiveKnn\",\n",
    "            kind=VectorSearchAlgorithmKind.EXHAUSTIVE_KNN,\n",
    "            parameters=ExhaustiveKnnParameters(\n",
    "                metric=VectorSearchAlgorithmMetric.COSINE\n",
    "            )\n",
    "        )\n",
    "    ],\n",
    "    profiles=[\n",
    "        VectorSearchProfile(\n",
    "            name=\"myHnswProfile\",\n",
    "            algorithm_configuration_name=\"myHnsw\",\n",
    "        ),\n",
    "        VectorSearchProfile(\n",
    "            name=\"myExhaustiveKnnProfile\",\n",
    "            algorithm_configuration_name=\"myExhaustiveKnn\",\n",
    "        )\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure semantic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import SemanticConfiguration from azure ai search\n",
    "semantic_config = SemanticConfiguration(\n",
    "    name=\"my-semantic-config\",\n",
    "    prioritized_fields=SemanticPrioritizedFields(\n",
    "            title_field=SemanticField(field_name=\"title\"),\n",
    "            # prioritized_keywords_fields=[SemanticField(field_name=\"Category\")],\n",
    "            content_fields=[SemanticField(field_name=\"text\")]\n",
    "    )\n",
    ")\n",
    "\n",
    "semantic_settings = SemanticSearch(configurations=[semantic_config])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cors_options = CorsOptions(allowed_origins=[\"*\"], max_age_in_seconds=60)\n",
    "scoring_profiles = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding data using OpenAI model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt  \n",
    "\n",
    "openai_client = AzureOpenAI(\n",
    "    api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "    api_version = \"2023-05-15\",\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    ")\n",
    "\n",
    "model = \"text-embedding-ada-002-v2\"\n",
    "\n",
    "# Generate Document Embeddings using OpenAI Ada 002\n",
    "# Read the text-sample.json\n",
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
    "# Function to generate embeddings for title and content fields, also used for query embeddings\n",
    "def generate_embeddings(text, model=model):\n",
    "    return openai_client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "\n",
    "# create documents for corpus\n",
    "documents = []\n",
    "for id in corpus:\n",
    "    #print(id)\n",
    "    documents.append({\n",
    "        \"corpusId\": id,\n",
    "        \"title\": corpus[id][\"title\"],\n",
    "        \"text\": corpus[id][\"text\"],\n",
    "        \"titleVector\": generate_embeddings(corpus[id][\"title\"]),\n",
    "        \"textVector\": generate_embeddings(corpus[id][\"text\"])\n",
    "    })\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload dataset into Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Upload documents to the index per 100 documents\n",
    "    print(\"documents size is\", len(documents))\n",
    "    if len(documents) > 1000:\n",
    "        for i in range(0, len(documents), 1000):\n",
    "            result = search_client.upload_documents(documents=documents[i:i+1000])\n",
    "            print(\"Upload of new document succeeded: {}\".format(result[0].succeeded))\n",
    "    else:\n",
    "            result = search_client.upload_documents(documents=documents)\n",
    "            print(\"Upload of new document succeeded: {}\".format(result[0].succeeded))\n",
    "except Exception as e:\n",
    "    print (e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full text search (simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.\"\n",
    "\n",
    "results = search_client.search(\n",
    "    search_text=query, \n",
    "    include_total_count=True, \n",
    "    top=5,\n",
    "    query_type=\"simple\")\n",
    "for result in results:\n",
    "    print(result[\"@search.score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.\"\n",
    "\n",
    "results = search_client.search(\n",
    "    search_text=query, \n",
    "    include_total_count=True, \n",
    "    top=50,\n",
    "    query_type=\"semantic\",\n",
    "    semantic_configuration_name='my-semantic-config')\n",
    "for result in results:\n",
    "    print(result[\"@search.score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hnsw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.\"\n",
    "vector_query = VectorizedQuery(\n",
    "    vector=generate_embeddings(query),\n",
    "    k_nearest_neighbors=3,\n",
    "    fields=\"titleVector, textVector\",\n",
    ")\n",
    "\n",
    "results = search_client.search(\n",
    "    search_text=None, \n",
    "    vector_queries=[vector_query], \n",
    "    include_total_count=True, \n",
    "    top=50)\n",
    "for result in results:\n",
    "    print(result[\"@search.score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exhausive KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.\"\n",
    "vector_query = VectorizedQuery(\n",
    "    vector=generate_embeddings(query),\n",
    "    k_nearest_neighbors=3,\n",
    "    fields=\"titleVector, textVector\",\n",
    "    exhaustive=True\n",
    ")\n",
    "\n",
    "results = search_client.search(\n",
    "    search_text=None, \n",
    "    vector_queries=[vector_query], \n",
    "    include_total_count=True, \n",
    "    top=50,\n",
    "    )\n",
    "for result in results:\n",
    "    print(result[\"@search.score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.\"\n",
    "vector_query = VectorizedQuery(\n",
    "    vector=generate_embeddings(query),\n",
    "    k_nearest_neighbors=3,\n",
    "    fields=\"titleVector, textVector\",\n",
    ")\n",
    "\n",
    "results = search_client.search(\n",
    "    search_text=query, \n",
    "    vector_queries=[vector_query], \n",
    "    include_total_count=True, \n",
    "    top=5,\n",
    "    query_type=\"semantic\",\n",
    "    semantic_configuration_name='my-semantic-config')\n",
    "for result in results:\n",
    "    print(result[\"@search.score\"])\n",
    "    print(result[\"@search.reranker_score\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "beir",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
