{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from beir import util, LoggingHandler\n",
    "from beir.datasets.data_loader import GenericDataLoader\n",
    "from beir.retrieval.evaluation import EvaluateRetrieval\n",
    "from beir.retrieval.search.lexical import BM25Search as BM25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                    level=logging.CRITICAL,\n",
    "                    handlers=[LoggingHandler()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"hotpotqa\"\n",
    "url = \"https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/{}.zip\".format(dataset)\n",
    "out_dir = \"./datasets\"\n",
    "data_path = util.download_and_unzip(url, out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus, queries, qrels = GenericDataLoader(data_path).load(split=\"test\")# pull data from corpus and queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents.indexes import SearchIndexClient \n",
    "from azure.search.documents import SearchClient\n",
    "\n",
    "\n",
    "service_name = \"fta-ai-search\"\n",
    "admin_key = os.environ[\"SEARCH_ADMIN_KEY\"]\n",
    "\n",
    "index_name = dataset\n",
    "\n",
    "# Create an SDK client\n",
    "endpoint = \"https://{}.search.windows.net/\".format(service_name)\n",
    "admin_client = SearchIndexClient(endpoint=endpoint,\n",
    "                      index_name=index_name,\n",
    "                      credential=AzureKeyCredential(admin_key))\n",
    "\n",
    "search_client = SearchClient(endpoint=endpoint,\n",
    "                      index_name=index_name,\n",
    "                      credential=AzureKeyCredential(admin_key))\n",
    "\n",
    "try:\n",
    "    result = admin_client.delete_index(index_name)\n",
    "    print ('Index', index_name, 'Deleted')\n",
    "except Exception as ex:\n",
    "    print (ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes.models import (\n",
    "    CorsOptions,\n",
    "    SearchableField,\n",
    "    SimpleField,\n",
    "    SearchIndex,\n",
    "    SearchFieldDataType\n",
    ")\n",
    "\n",
    "\n",
    "fields = [\n",
    "    SimpleField(name=\"corpusId\", type=SearchFieldDataType.String, key=True),\n",
    "    SearchableField(name=\"title\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"text\", type=SearchFieldDataType.String),\n",
    "]\n",
    "cors_options = CorsOptions(allowed_origins=[\"*\"], max_age_in_seconds=60)\n",
    "scoring_profiles = []\n",
    "index = SearchIndex(\n",
    "    name=index_name,\n",
    "    fields=fields,\n",
    "    scoring_profiles=scoring_profiles,\n",
    "    cors_options=cors_options)\n",
    "\n",
    "\n",
    "try:\n",
    "    result = admin_client.create_index(index)\n",
    "    print ('Index', result.name, 'created')\n",
    "except Exception as ex:\n",
    "    print (ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create documents for corpus\n",
    "documents = []\n",
    "for id in corpus:\n",
    "    #print(id)\n",
    "    documents.append({\n",
    "        \"corpusId\": id,\n",
    "        \"title\": corpus[id][\"title\"],\n",
    "        \"text\": corpus[id][\"text\"]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    result = search_client.upload_documents(documents=documents)\n",
    "    print(\"Upload of new document succeeded: {}\".format(result[0].succeeded))\n",
    "except Exception as ex:\n",
    "    print (ex.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search an index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = search_client.search(search_text=\"*\", include_total_count=True)\n",
    "\n",
    "print ('Total Documents Matching Query:', results.get_count())\n",
    "# for result in results:\n",
    "#     print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = search_client.search(search_text=\"Micro\", include_total_count=True, select='corpusId, title, text')\n",
    "\n",
    "print ('Total Documents Matching Query:', results.get_count())\n",
    "# for result in results:\n",
    "#     print(\"corpusId:\", result[\"corpusId\"])\n",
    "#     print(\"title\", result[\"title\"])\n",
    "#     print(\"text\", result[\"text\"][:100], \"...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_ids = list(queries)\n",
    "dict_results = {}\n",
    "for query_id in query_ids:\n",
    "    query = queries[query_id]\n",
    "    results = search_client.search(search_text=query, include_total_count=True, select='corpusId, title, text', top=5)\n",
    "    id_score = {}\n",
    "    for result in results:\n",
    "        id_score[result[\"corpusId\"]] = result[\"@search.score\"]\n",
    "    # print(id_score)\n",
    "    dict_results[query_id] = id_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beir.retrieval.evaluation import EvaluateRetrieval\n",
    "ndcg, _map, recall, precision = EvaluateRetrieval.evaluate(qrels, dict_results, [1, 3, 5, 10, 50, 100, 1000])\n",
    "print(ndcg, _map, recall, precision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "beir",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
